[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ana Jaramillo’s Website",
    "section": "",
    "text": "I am a current Biology major and Mathematics & Statistics minor at Pomona College. This is my landing page for data science, bioinformatics, and computing projects."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I guess theres nothing to learn about me at this time."
  },
  {
    "objectID": "TidyTuesdays.html",
    "href": "TidyTuesdays.html",
    "title": "TidyTuesdays",
    "section": "",
    "text": "something in here"
  },
  {
    "objectID": "TT2.html",
    "href": "TT2.html",
    "title": "TidyTuesday #2",
    "section": "",
    "text": "Data was sourced from US Egg Production Data by jonthegeek on Github\n\n# Packages\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n# Data\neggproduction  &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-04-11/egg-production.csv')\n\n\n# Filter by year\neggproduction |&gt;\n  select(observed_month, n_hens, n_eggs) |&gt;\n  filter(str_starts(as.character(observed_month), \"2020\"))\n\n# A tibble: 48 × 3\n   observed_month   n_hens     n_eggs\n   &lt;date&gt;            &lt;dbl&gt;      &lt;dbl&gt;\n 1 2020-01-31     64019000 1221400000\n 2 2020-02-29     64384000 1154100000\n 3 2020-03-31     64730000 1239900000\n 4 2020-04-30     65044000 1203500000\n 5 2020-05-31     64481000 1239100000\n 6 2020-06-30     64251000 1207400000\n 7 2020-07-31     64353000 1255200000\n 8 2020-08-31     64223000 1257100000\n 9 2020-09-30     63975000 1219800000\n10 2020-10-31     63728000 1254800000\n# ℹ 38 more rows\n\n# Plotting\nggplot(eggproduction, aes(x = observed_month, y = n_eggs/n_hens)) +\n  geom_point() +\n  labs(\n    title = \"Number of eggs laid per hen in 2020\",\n    subtitle = \"*Assuming every hen laid the same number of eggs\",\n    x = \"Date\",\n    y = \"Number of Eggs\"\n  )"
  },
  {
    "objectID": "TT1.html",
    "href": "TT1.html",
    "title": "TidyTuesday #1",
    "section": "",
    "text": "Data was sourced from Numbats in Australia by jonthegeek on Github\n\n# Packages\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n# Data\nnumbats &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-03-07/numbats.csv')\n\n# Filtering Data\nnumbats |&gt;\n  select(decimalLatitude, decimalLongitude, scientificName) |&gt;\n  filter(scientificName == \"Myrmecobius fasciatus\")\n\n# A tibble: 787 × 3\n   decimalLatitude decimalLongitude scientificName       \n             &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;                \n 1           -37.6             146. Myrmecobius fasciatus\n 2           -35.1             150. Myrmecobius fasciatus\n 3           -35               118. Myrmecobius fasciatus\n 4           -34.7             118. Myrmecobius fasciatus\n 5           -34.6             117. Myrmecobius fasciatus\n 6           -34.6             117. Myrmecobius fasciatus\n 7           -34.6             118. Myrmecobius fasciatus\n 8           -34.6             117. Myrmecobius fasciatus\n 9           -34.6             117. Myrmecobius fasciatus\n10           -34.6             117. Myrmecobius fasciatus\n# ℹ 777 more rows\n\n# Making Plots\nggplot(data = numbats, aes(x = decimalLatitude, y = decimalLongitude)) +\n  geom_point() +\n  labs(title = \"Coordinates of 787 Numbats (Myrmecobius fasciatus)\", x = \"Coordinate Latitude\", y = \"Coordinate Longitude\")"
  },
  {
    "objectID": "Mini Project 2.html",
    "href": "Mini Project 2.html",
    "title": "Mini Project 2",
    "section": "",
    "text": "Data was sourced from The Office Lines on Kaggle by Fabriziocominetti\nThe Office is a comedy show following the lifestyle of seemingly normal office workers. As the show follows multiple characters, there is some debate as to who exactly the main character is. As such, I have decided to count the amount of words spoken by each character per season to better understand who the show writers center most. Additionally, as a young adult show, there is some occasional cussing which occurs throughout. Here, I have quantified the percentage of the show script which involves cussing to see how much of the show involves potty-mouth humor.\n\n# Data\nlibrary(tidyverse)\n\nofficelines &lt;- read_csv(\"the-office_lines.csv\")\n\n# Cleaning Data\nofficelines &lt;- officelines |&gt;\nmutate(Line = str_to_lower(Line))\n\nlines &lt;- officelines$Line\nlines &lt;- str_remove_all(lines, \"[[:punct:]]\")\n\nofficelines &lt;- officelines |&gt;\nselect(Character, Line, Season, Episode_Number) |&gt;\nmutate(Line = lines) \n\n\nGraph 1 (Who says the most words per season?)\nCleaning data:\n\n# Homogenizing the lines\nwords_per_char &lt;- officelines |&gt;\nmutate(word_count = lengths(str_split(Line, \"\\\\s+\"))) |&gt;\ngroup_by(Character, Season) |&gt;\nsummarize(total_words = sum(word_count))\n\n#Keeping only Main Characters & Cleaning Data\nmain_characters &lt;- c(\"Michael\", \"Jim\", \"Pam\", \"Dwight\", \"Andy\", \"Ryan\", \"Robert\")\n\nwords_dont_keep &lt;- c(\"Voicemail\", \"Mom\", \"Dad\", \"Ad\", \"Fake\", \"Except\", \"Church\")\n\nword_pattern_keep &lt;- paste0(\"\\\\b(\", paste(main_characters, collapse = \"|\"), \")\\\\b\")\n\nword_pattern_delete &lt;- paste0(\"\\\\b(\", paste(words_dont_keep, collapse = \"|\"), \")\\\\b\")\n\nget_rid_ands &lt;- \"\\\\s&\\\\s|\\\\sAnd\\\\s|/|,\\\\s\"\n\nwords_per_char &lt;- words_per_char |&gt;\nfilter(str_detect(Character, word_pattern_keep)) |&gt;\nfilter(!str_detect(Character, word_pattern_delete)) |&gt;\nmutate(Character = str_replace_all(Character, get_rid_ands, \", \")) |&gt;\nseparate_rows(Character, sep = \", \") |&gt;\nfilter(str_detect(Character, word_pattern_keep)) |&gt;\nmutate(Character = case_when(\nstr_detect(Character, \"\\\\bJim\\\\b\") ~ \"Jim\",\nstr_detect(Character, \"\\\\bPam\\\\b\") ~ \"Pam\",\nstr_detect(Character, \"\\\\bDwight\\\\b\") ~ \"Dwight\",\nstr_detect(Character, \"\\\\bMichael\\\\b\") ~ \"Michael\",\nstr_detect(Character, \"\\\\bAndy\\\\b\") ~ \"Andy\",\nstr_detect(Character, \"\\\\bRobert\\\\b\") ~ \"Robert\", str_detect(Character, \"\\\\bRyan\\\\b\") ~ \"Ryan\")) |&gt;\ngroup_by(Character, Season) |&gt;\nsummarise(total_words = sum(total_words), .groups = 'drop') \n\n\n\nFinally! Graphing!!!\n\nggplot(words_per_char, aes(x = Character, y = total_words, fill = Character)) +\ngeom_bar(stat = \"identity\") +\nfacet_wrap(~Season) +\ntheme_minimal() +\nlabs(\ntitle = \"Who says the most words in The Office?\",\nsubtitle = \"Main characters selected via The Office Wiki\",\nx = \"Season\", \ny = \"Total Words Spoken\") +\n  theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\n\nThe figure shows the total number of words spoken by each of the main characters (Andy, Dwight, Jim, Michael, Pam, Robert, and Ryan) over the course of a season. Though this data visualization, you can see that Michael is the character who speaks the most (word-wise) throughout seasons 1-7. He was not present in season 8 & 9 (denoted by a lack of words). The character with the second most words throughout seasons 1-8 (except for season 4) is Dwight, who ends up having the most words in season 9. In season 8, Andy has the most words. On average Robert has no words per season, except for a slight amount of words in season 7 and more words in season 8. Ryan also has very few words throughout the show but is consistently present unlike Robert. The legend shows a color-coded labeling system for each of the main character. The x-axis denotes the Season (with number labeling shown above the graphs) and the y-axis shows the total words spoken.\n\n\nGraph 2 (What percentage of the show involves cussing?)\n\n# Working on the data\ntotal_words &lt;- officelines |&gt;\n  mutate(word_count = lengths(str_split(Line, \"\\\\s+\"))) |&gt;\n  summarize(total_words = sum(word_count))\n\n\nbad_words &lt;- c(\"fuck\", \"bitch\", \"shit\", \"mother-fucker\", \"mother fucker\", \"dumb-ass\", \"dumb ass\", \"dumbass\", \"god damn\", \"goddamn\", \"god dammit\", \"goddammit\", \"dick-head\", \"dickhead\", \"goddamned\", \"whore\", \"slut\", \"ass\", \"bastard\", \"bullshit\", \"damned\", \"damn\", \"dick\", \"hell\", \"prick\", \"piss\", \"wanker\", \"retard\", \"crap\", \"douche\")\n\nbad_words_pattern &lt;- paste0(\"\\\\b(\", paste(bad_words, collapse = \"|\"), \")\\\\b\")\n\nofficelines &lt;- officelines |&gt;\n  filter(!is.na(Line)) |&gt;\n  rowwise() |&gt;\n  mutate(bad_word_count = sum(str_count(Line, bad_words_pattern))) |&gt;\n    ungroup()\n\nlst_of_bw_count &lt;- officelines$bad_word_count\ntotal_bad_words &lt;- sum(lst_of_bw_count)\n\nlst_total_words &lt;- total_words$total_words\n\nwordsdf &lt;- data.frame(\n  totalwords = lst_total_words,\n  unfriendly_words = total_bad_words\n)\n\nwordsdf &lt;- wordsdf |&gt;\n  mutate(bad_words_perc = unfriendly_words/totalwords * 100) |&gt;\n  mutate(good_words_perc = (100 - bad_words_perc))\n\n# Graphing\n\nslices &lt;- c(wordsdf$good_words_perc, wordsdf$bad_words_perc)\nlabels &lt;- c(\"Family Friendly Words, 99.9%\", \"Bad Words, ~0.1%\")\npie(slices, labels = labels, main = \"Percentage of Bad Words Used in The Office\", col = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\nThis graph clearly shows the lack of swear words in proportion to the rest of the show dialogue throughout the 9 seasons, with swear words only making up about 1% of the show’s total words. This show is rated PG-13, which may explain the lack of cussing and an under-reliance of potty-mouth humor. Blue denotes the family-friendly words, and red (although not very visible) displays the swear words. Percentage labeling is included next to the slice tick-marks to aid with quantifying percentages."
  }
]